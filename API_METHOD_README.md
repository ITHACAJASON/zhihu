# çŸ¥ä¹APIçˆ¬è™«æ–¹æ³•

## ğŸ“‹ å®ŒæˆçŠ¶æ€

âœ… **APIè®¤è¯é—®é¢˜å·²è§£å†³**
âœ… **æ•°æ®è§£æé€»è¾‘å·²å®Œå–„**
âœ… **é›†æˆåˆ°ä¸»æµç¨‹**
âœ… **å®Œæ•´æµ‹è¯•é€šè¿‡**

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. æµ‹è¯•APIè¿æ¥

```bash
# æµ‹è¯•APIè¿æ¥æ˜¯å¦æ­£å¸¸
python3 zhihu_api_main.py test
```

### 2. çˆ¬å–å•ä¸ªé—®é¢˜ç­”æ¡ˆ

```bash
# ä½¿ç”¨APIæ–¹æ³•çˆ¬å–æŒ‡å®šé—®é¢˜çš„æ‰€æœ‰ç­”æ¡ˆ
python3 zhihu_api_main.py crawl --question-url "https://www.zhihu.com/question/354793553"

# é™åˆ¶ç­”æ¡ˆæ•°é‡
python3 zhihu_api_main.py crawl --question-url "https://www.zhihu.com/question/354793553" --max-answers 10

# æŒ‡å®šä»»åŠ¡ID
python3 zhihu_api_main.py crawl --question-url "https://www.zhihu.com/question/354793553" --task-id "my_task"
```

### 3. æ‰¹é‡çˆ¬å–

```bash
# æ‰¹é‡çˆ¬å–å¤šä¸ªé—®é¢˜çš„ç­”æ¡ˆ
python3 zhihu_api_main.py batch --question-urls "https://www.zhihu.com/question/123" "https://www.zhihu.com/question/456"

# é™åˆ¶æ¯ä¸ªé—®é¢˜çš„ç­”æ¡ˆæ•°é‡
python3 zhihu_api_main.py batch --question-urls "https://www.zhihu.com/question/123" --max-answers 5
```

### 4. åœ¨Pythonä»£ç ä¸­ä½¿ç”¨

```python
from zhihu_api_main import ZhihuAPIMain

# åˆå§‹åŒ–
crawler = ZhihuAPIMain()

# çˆ¬å–å•ä¸ªé—®é¢˜
result = crawler.crawl_question_answers_api(
    question_url="https://www.zhihu.com/question/354793553",
    max_answers=10
)

print(f"è·å–åˆ° {result['total_answers']} ä¸ªç­”æ¡ˆ")

# æ‰¹é‡çˆ¬å–
results = crawler.batch_crawl_answers_api(
    question_urls=["https://www.zhihu.com/question/123", "https://www.zhihu.com/question/456"],
    max_answers_per_question=5
)
```

## ğŸ› ï¸ æŠ€æœ¯ç‰¹æ€§

### âœ… æ ¸å¿ƒåŠŸèƒ½
- **å®Œæ•´çš„APIè®¤è¯** - ä½¿ç”¨çœŸå®çš„æµè§ˆå™¨cookieså’Œè¯·æ±‚å¤´
- **æ™ºèƒ½æ•°æ®è§£æ** - è‡ªåŠ¨å¤„ç†feedsç«¯ç‚¹çš„æ•°æ®ç»“æ„
- **åˆ†é¡µæ”¯æŒ** - è‡ªåŠ¨è·å–æ‰€æœ‰ç­”æ¡ˆé¡µé¢
- **é”™è¯¯é‡è¯•** - ç½‘ç»œå¼‚å¸¸è‡ªåŠ¨é‡è¯•æœºåˆ¶
- **æ•°æ®åº“é›†æˆ** - è‡ªåŠ¨ä¿å­˜åˆ°PostgreSQLæ•°æ®åº“

### âœ… æŠ€æœ¯ä¼˜åŠ¿
- âš¡ **é€Ÿåº¦å¿«** - ç›´æ¥è°ƒç”¨APIï¼Œæ— éœ€è§£æHTML
- ğŸ¯ **æ•°æ®å®Œæ•´** - è·å–ç»“æ„åŒ–ç­”æ¡ˆæ•°æ®
- ğŸ”„ **ç¨³å®šæ€§é«˜** - APIæ¥å£ç›¸å¯¹ç¨³å®š
- ğŸ“Š **æ˜“äºåˆ†æ** - JSONæ ¼å¼æ•°æ®ä¾¿äºå¤„ç†

### âœ… å®‰å…¨ç‰¹æ€§
- ğŸ›¡ï¸ **çœŸå®è¯·æ±‚å¤´** - æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¯·æ±‚
- ğŸ” **Cookiesç®¡ç†** - è‡ªåŠ¨åŠ è½½å’Œæ›´æ–°cookies
- ğŸš¦ **é¢‘ç‡æ§åˆ¶** - å†…ç½®å»¶æ—¶é¿å…è¯·æ±‚è¿‡å¿«
- ğŸ“ **æ—¥å¿—è®°å½•** - è¯¦ç»†çš„æ“ä½œæ—¥å¿—

## ğŸ“ æ–‡ä»¶ç»“æ„

```
zhihu/
â”œâ”€â”€ zhihu_api_main.py          # APIçˆ¬è™«ä¸»ç¨‹åº
â”œâ”€â”€ zhihu_api_crawler.py       # APIçˆ¬è™«æ ¸å¿ƒé€»è¾‘
â”œâ”€â”€ demo_api_crawler.py        # APIåŠŸèƒ½æ¼”ç¤º
â”œâ”€â”€ check_api_cookies.py       # APIè¿æ¥æµ‹è¯•
â”œâ”€â”€ test_direct_access.py      # ç›´æ¥é¡µé¢è®¿é—®æµ‹è¯•
â”œâ”€â”€ cookies/zhihu_cookies.json # æµè§ˆå™¨cookies
â””â”€â”€ cache/zhihu_cookies.pkl    # åºåˆ—åŒ–cookies
```

## ğŸ”§ é…ç½®è¯´æ˜

### Cookiesæ›´æ–°
å½“é‡åˆ°403é”™è¯¯æ—¶ï¼Œéœ€è¦æ›´æ–°cookiesï¼š

```bash
# 1. åœ¨æµè§ˆå™¨ä¸­è®¿é—®çŸ¥ä¹å¹¶ç™»å½•
# 2. æŒ‰F12æ‰“å¼€å¼€å‘è€…å·¥å…·
# 3. è®¿é—®ä»»æ„çŸ¥ä¹é—®é¢˜é¡µé¢
# 4. å¤åˆ¶Networkæ ‡ç­¾é¡µä¸­APIè¯·æ±‚çš„å®Œæ•´cookies
# 5. æ›´æ–° cookies/zhihu_cookies.json æ–‡ä»¶
# 6. è¿è¡Œæ›´æ–°è„šæœ¬ï¼š
python3 -c "
import json
import pickle
import os

# è¯»å–JSON cookies
with open('cookies/zhihu_cookies.json', 'r', encoding='utf-8') as f:
    cookies_data = json.load(f)

# è½¬æ¢ä¸ºpickleæ ¼å¼
os.makedirs('cache', exist_ok=True)
with open('cache/zhihu_cookies.pkl', 'wb') as f:
    pickle.dump(cookies_data, f)

print('âœ“ Cookieså·²æ›´æ–°')
"
```

### æ•°æ®åº“é…ç½®
ç¡®ä¿PostgreSQLæ•°æ®åº“å·²é…ç½®ï¼š

```python
# åœ¨ config.py ä¸­è®¾ç½®æ•°æ®åº“è¿æ¥ä¿¡æ¯
POSTGRES_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'zhihu_crawler',
    'user': 'your_username',
    'password': 'your_password'
}
```

## ğŸ“Š APIæ•°æ®ç»“æ„

### è¯·æ±‚å‚æ•°
```javascript
{
  "include": "data[*].is_normal,admin_closed_comment,reward_info,...",
  "offset": "",
  "limit": "20",
  "order": "default",
  "ws_qiangzhisafe": "0",
  "platform": "desktop",
  "session_id": "1756125566118409"
}
```

### å“åº”ç»“æ„
```javascript
{
  "data": [
    {
      "target_type": "answer",
      "target": {
        "id": "ç­”æ¡ˆID",
        "content": "ç­”æ¡ˆå†…å®¹HTML",
        "author": {
          "name": "ä½œè€…å§“å",
          "url_token": "ä½œè€…æ ‡è¯†"
        },
        "created_time": æ—¶é—´æˆ³,
        "voteup_count": ç‚¹èµæ•°,
        "comment_count": è¯„è®ºæ•°
      }
    }
  ],
  "paging": {
    "is_end": false,
    "next": "ä¸‹ä¸€é¡µURL"
  }
}
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **403 Forbiddené”™è¯¯**
   - æ£€æŸ¥cookiesæ˜¯å¦è¿‡æœŸ
   - æ›´æ–° `cookies/zhihu_cookies.json`
   - é‡æ–°ç”Ÿæˆpickleæ–‡ä»¶

2. **è¿”å›ç©ºæ•°æ®**
   - å¯èƒ½æ˜¯é—®é¢˜å·²è¢«åˆ é™¤æˆ–æ— å…¬å¼€ç­”æ¡ˆ
   - æ£€æŸ¥é—®é¢˜URLæ˜¯å¦æ­£ç¡®
   - å°è¯•å…¶ä»–é—®é¢˜æµ‹è¯•

3. **ç½‘ç»œè¶…æ—¶**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - ç¨‹åºä¼šè‡ªåŠ¨é‡è¯•å¤±è´¥çš„è¯·æ±‚

### è°ƒè¯•æ–¹æ³•

```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
tail -f logs/zhihu_crawler.log

# æµ‹è¯•å•ä¸ªAPIè°ƒç”¨
python3 check_api_cookies.py

# æ¼”ç¤ºåŠŸèƒ½
python3 demo_api_crawler.py
```

## ğŸ¯ ä½¿ç”¨å»ºè®®

1. **å®šæœŸæ›´æ–°cookies** - é¿å…è®¤è¯è¿‡æœŸ
2. **åˆç†è®¾ç½®å»¶æ—¶** - é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
3. **ç›‘æ§æ—¥å¿—** - åŠæ—¶å‘ç°å’Œè§£å†³é—®é¢˜
4. **æ•°æ®å¤‡ä»½** - å®šæœŸå¤‡ä»½æ•°æ®åº“ä¸­çš„æ•°æ®

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

| ç‰¹æ€§ | Seleniumæ–¹æ³• | APIæ–¹æ³• |
|------|-------------|---------|
| é€Ÿåº¦ | ğŸŒ è¾ƒæ…¢ | âš¡ å¾ˆå¿« |
| ç¨³å®šæ€§ | ğŸ¯ ä¸€èˆ¬ | ğŸ”’ é«˜ |
| æ•°æ®å®Œæ•´æ€§ | ğŸ“Š ä¸€èˆ¬ | ğŸ¯ é«˜ |
| ç»´æŠ¤æˆæœ¬ | ğŸ”§ é«˜ | âš™ï¸ ä½ |
| åçˆ¬è™«é£é™© | ğŸ›¡ï¸ é«˜ | ğŸ›¡ï¸ ä½ |

## ğŸ”„ é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ

APIæ–¹æ³•å¯ä»¥ä¸ç°æœ‰çš„Seleniumæ–¹æ³•æ··åˆä½¿ç”¨ï¼š

```python
from api_integration import IntegratedZhihuCrawler

# ä½¿ç”¨æ··åˆæ¨¡å¼ï¼šSeleniumæœç´¢ + APIè·å–ç­”æ¡ˆ
crawler = IntegratedZhihuCrawler(
    headless=True,
    use_api_for_answers=True  # å¯ç”¨APIç­”æ¡ˆè·å–
)

result = crawler.crawl_by_keyword_hybrid(
    keyword="äººå·¥æ™ºèƒ½",
    max_questions=5,
    max_answers_per_question=10
)
```

---

ğŸ‰ **APIæ–¹æ³•å¼€å‘å®Œæˆï¼** ç°åœ¨ä½ æ‹¥æœ‰äº†ä¸€ä¸ªåŠŸèƒ½å®Œæ•´ã€é«˜æ•ˆç¨³å®šçš„çŸ¥ä¹ç­”æ¡ˆçˆ¬è™«ï¼

