#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import time
import logging
import signal
from typing import List, Tuple

from database import DatabaseManager
from zhihu_crawler import ZhihuCrawler
from config import (
    setup_logging, 
    get_database_config, 
    get_crawler_config
)

class ZhihuCrawlerApp:
    """çŸ¥ä¹çˆ¬è™«åº”ç”¨ä¸»ç±»"""
    
    def __init__(self):
        self.db_manager = None
        self.crawler = None
        self.running = True
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
    
    def signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨ï¼Œç”¨äºä¼˜é›…é€€å‡º"""
        print("\næ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨å®‰å…¨å…³é—­...")
        self.running = False
        self.cleanup()
        sys.exit(0)
    
    def setup(self) -> bool:
        """åˆå§‹åŒ–åº”ç”¨"""
        try:
            # è®¾ç½®æ—¥å¿—
            setup_logging()
            logging.info("çŸ¥ä¹çˆ¬è™«åº”ç”¨å¯åŠ¨")
            
            # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
            db_config = get_database_config()
            self.db_manager = DatabaseManager(**db_config)
            
            if not self.db_manager.connect():
                logging.error("æ•°æ®åº“è¿æ¥å¤±è´¥")
                return False
            
            # åˆå§‹åŒ–çˆ¬è™«
            crawler_config = get_crawler_config()
            self.crawler = ZhihuCrawler(
                db_manager=self.db_manager,
                headless=crawler_config['headless']
            )
            
            self.crawler.setup_driver()
            
            logging.info("åº”ç”¨åˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            logging.error(f"åº”ç”¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def run(self):
        """è¿è¡Œçˆ¬è™«åº”ç”¨"""
        try:
            if not self.setup():
                print("åº”ç”¨åˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡º")
                return
            
            # ç­‰å¾…ç”¨æˆ·ç™»å½•
            print("\n=== çŸ¥ä¹çˆ¬è™«å¯åŠ¨ ===")
            if not self.crawler.wait_for_login():
                print("ç”¨æˆ·å–æ¶ˆç™»å½•ï¼Œé€€å‡ºåº”ç”¨")
                return
            
            # æŒç»­è¿è¡Œç›´åˆ°å®Œæˆé‡‡é›†
            while self.running:
                # è·å–å¾…çˆ¬å–çš„é—®é¢˜åˆ—è¡¨
                questions = self.get_questions_to_crawl()
                if not questions:
                    print("\nğŸ‰ æ‰€æœ‰é—®é¢˜å·²å®Œæˆé‡‡é›†ï¼")
                    break
                
                print(f"\næ‰¾åˆ° {len(questions)} ä¸ªå¾…çˆ¬å–çš„é—®é¢˜")
                
                # å¼€å§‹çˆ¬å–
                success = self.crawl_questions(questions)
                
                # å¦‚æœå…¨éƒ¨æˆåŠŸæˆ–ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºå¾ªç¯
                if success or not self.running:
                    break
                    
                # å¦‚æœæœ‰å¤±è´¥çš„ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
                print("\nç­‰å¾… 30 ç§’åé‡æ–°æ£€æŸ¥å¾…é‡‡é›†é—®é¢˜...")
                for i in range(30):
                    if not self.running:
                        break
                    time.sleep(0.33)
            
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
        except Exception as e:
            logging.error(f"åº”ç”¨è¿è¡Œå‡ºé”™: {e}")
        finally:
            self.cleanup()
    
    def get_questions_to_crawl(self) -> List[Tuple[str, int]]:
        """è·å–å¾…çˆ¬å–çš„é—®é¢˜åˆ—è¡¨"""
        try:
            questions = self.db_manager.get_questions()
            
            # è¿‡æ»¤å·²å®Œæˆçš„é—®é¢˜
            filtered_questions = []
            for url, answer_count in questions:
                crawled_count = self.db_manager.get_crawled_count(url)
                if crawled_count < answer_count:
                    filtered_questions.append((url, answer_count))
                    logging.info(f"é—®é¢˜ {url}: ç›®æ ‡ {answer_count} ä¸ªå›ç­”ï¼Œå·²çˆ¬å– {crawled_count} ä¸ª")
                else:
                    logging.info(f"é—®é¢˜ {url} å·²å®Œæˆçˆ¬å–")
            
            return filtered_questions
            
        except Exception as e:
            logging.error(f"è·å–é—®é¢˜åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def crawl_questions(self, questions: List[Tuple[str, int]]) -> bool:
        """æ‰¹é‡çˆ¬å–é—®é¢˜"""
        total_questions = len(questions)
        success_count = 0
        total_answers = 0
        start_time = time.time()
        
        print(f"\n=== å¼€å§‹é‡‡é›† {total_questions} ä¸ªé—®é¢˜ ===")
        
        for i, (url, target_count) in enumerate(questions, 1):
            if not self.running:
                break
                
            current_time = time.time()
            elapsed_time = current_time - start_time
            
            print(f"\n[{i}/{total_questions}] å¼€å§‹é‡‡é›†é—®é¢˜: {url}")
            print(f"ç›®æ ‡å›ç­”æ•°: {target_count}, å·²ç”¨æ—¶: {elapsed_time:.1f}ç§’")
            
            try:
                # æ£€æŸ¥å·²çˆ¬å–æ•°é‡
                crawled_count = self.db_manager.get_crawled_count(url)
                remaining_count = target_count - crawled_count
                
                if remaining_count <= 0:
                    print(f"âœ… é—®é¢˜å·²å®Œæˆé‡‡é›†ï¼Œè·³è¿‡")
                    success_count += 1
                    total_answers += crawled_count
                    continue
                
                print(f"å·²é‡‡é›†: {crawled_count}ï¼Œè¿˜éœ€é‡‡é›†: {remaining_count}")
                
                # å¼€å§‹çˆ¬å–
                question_start_time = time.time()
                new_crawled = self.crawler.crawl_question_answers(url, target_count)
                question_end_time = time.time()
                
                # ç»Ÿè®¡ç»“æœ
                total_crawled = self.db_manager.get_crawled_count(url)
                completion_rate = (total_crawled / target_count) * 100
                
                if total_crawled >= target_count:
                    print(f"âœ… é‡‡é›†å®Œæˆï¼")
                    success_count += 1
                else:
                    print(f"âš ï¸  éƒ¨åˆ†å®Œæˆ")
                    
                print(f"æœ¬æ¬¡æ–°å¢: {new_crawled} ä¸ªå›ç­”")
                print(f"æ€»è®¡é‡‡é›†: {total_crawled} ä¸ªå›ç­”")
                print(f"å®Œæˆåº¦: {completion_rate:.1f}%")
                print(f"è€—æ—¶: {question_end_time - question_start_time:.1f} ç§’")
                
                total_answers += total_crawled
                
                # æ˜¾ç¤ºå®æ—¶è¿›åº¦
                progress = (i / total_questions) * 100
                print(f"æ€»è¿›åº¦: {progress:.1f}% ({i}/{total_questions}), æˆåŠŸ: {success_count}, æ€»å›ç­”æ•°: {total_answers}")
                
                # é—®é¢˜é—´éš”å·²å–æ¶ˆï¼Œç›´æ¥ç»§ç»­ä¸‹ä¸€ä¸ªé—®é¢˜
                    
            except Exception as e:
                logging.error(f"çˆ¬å–é—®é¢˜ {url} å¤±è´¥: {e}")
                print(f"âŒ é‡‡é›†å¤±è´¥: {e}")
                continue
        
        # æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - start_time
        print(f"\n=== æœ¬è½®é‡‡é›†å®Œæˆ ===")
        print(f"æ€»é—®é¢˜æ•°: {total_questions}")
        print(f"æˆåŠŸé‡‡é›†: {success_count}")
        print(f"å¤±è´¥æ•°é‡: {total_questions - success_count}")
        print(f"æ€»å›ç­”æ•°: {total_answers}")
        print(f"æ€»ç”¨æ—¶: {total_time:.1f} ç§’")
        if total_questions > 0:
            print(f"å¹³å‡æ¯ä¸ªé—®é¢˜: {total_time/total_questions:.1f} ç§’")
        
        self.print_summary(questions)
        
        # è¿”å›æ˜¯å¦å…¨éƒ¨æˆåŠŸ
        return success_count == total_questions
    
    def print_summary(self, questions: List[Tuple[str, int]]):
        """æ‰“å°çˆ¬å–æ€»ç»“"""
        print("\n=== çˆ¬å–æ€»ç»“ ===")
        
        total_target = 0
        total_crawled = 0
        completed_questions = 0
        
        for url, target_count in questions:
            crawled_count = self.db_manager.get_crawled_count(url)
            total_target += target_count
            total_crawled += crawled_count
            
            if crawled_count >= target_count:
                completed_questions += 1
            
            completion_rate = (crawled_count / target_count) * 100
            status = "âœ“" if crawled_count >= target_count else "â—‹"
            print(f"{status} {url}: {crawled_count}/{target_count} ({completion_rate:.1f}%)")
        
        overall_completion = (total_crawled / total_target) * 100 if total_target > 0 else 0
        
        print(f"\næ€»ä½“ç»Ÿè®¡:")
        print(f"é—®é¢˜æ€»æ•°: {len(questions)}")
        print(f"å®Œæˆé—®é¢˜: {completed_questions}")
        print(f"ç›®æ ‡å›ç­”æ€»æ•°: {total_target}")
        print(f"å®é™…çˆ¬å–æ€»æ•°: {total_crawled}")
        print(f"æ€»ä½“å®Œæˆåº¦: {overall_completion:.1f}%")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.crawler:
                self.crawler.close()
            
            if self.db_manager:
                self.db_manager.disconnect()
            
            logging.info("èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logging.error(f"èµ„æºæ¸…ç†å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    app = ZhihuCrawlerApp()
    app.run()

if __name__ == "__main__":
    main()