#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥ä¹APIçˆ¬è™«æ¼”ç¤º
å±•ç¤ºå®Œæ•´çš„APIçˆ¬å–åŠŸèƒ½
"""

import json
from zhihu_api_crawler import ZhihuAPIAnswerCrawler

def demo_api_crawler():
    """æ¼”ç¤ºAPIçˆ¬è™«åŠŸèƒ½"""
    print("ğŸš€ çŸ¥ä¹APIçˆ¬è™«åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)

    # åˆå§‹åŒ–APIçˆ¬è™«
    print("\n1. åˆå§‹åŒ–APIçˆ¬è™«...")
    crawler = ZhihuAPIAnswerCrawler()
    print("âœ“ APIçˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")

    # æµ‹è¯•APIè¿æ¥
    print("\n2. æµ‹è¯•APIè¿æ¥...")
    if crawler.test_api_connection():
        print("âœ“ APIè¿æ¥æµ‹è¯•æˆåŠŸ")
    else:
        print("âœ— APIè¿æ¥æµ‹è¯•å¤±è´¥")
        return

    # æ¼”ç¤ºAPIç­”æ¡ˆçˆ¬å–
    print("\n3. æ¼”ç¤ºAPIç­”æ¡ˆçˆ¬å–...")

    # ä½¿ç”¨ä¸€ä¸ªå·²çŸ¥æœ‰ç­”æ¡ˆçš„é—®é¢˜è¿›è¡Œæ¼”ç¤º
    test_questions = [
        {
            'url': 'https://www.zhihu.com/question/354793553',
            'description': 'æµ‹è¯•é—®é¢˜ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰'
        }
    ]

    for i, question in enumerate(test_questions, 1):
        print(f"\né—®é¢˜ {i}: {question['description']}")
        print(f"URL: {question['url']}")

        try:
            result = crawler.crawl_answers_by_question_url(
                question_url=question['url'],
                task_id=f"demo_task_{i}",
                max_answers=5,  # é™åˆ¶ç­”æ¡ˆæ•°é‡ç”¨äºæ¼”ç¤º
                save_to_db=False  # æ¼”ç¤ºæ¨¡å¼ï¼Œä¸ä¿å­˜åˆ°æ•°æ®åº“
            )

            print(f"  ğŸ“Š çˆ¬å–ç»“æœ:")
            print(f"    - ç­”æ¡ˆæ•°é‡: {result['total_answers']}")
            print(f"    - è€—æ—¶: {result['duration_seconds']:.2f} ç§’")
            print(f"    - ä»»åŠ¡ID: {result['task_id']}")

            if result['answers']:
                print("  ğŸ“ ç­”æ¡ˆé¢„è§ˆ:")
                for j, answer in enumerate(result['answers'][:2], 1):  # åªæ˜¾ç¤ºå‰2ä¸ª
                    print(f"    ç­”æ¡ˆ {j}:")
                    print(f"      ä½œè€…: {answer.author}")
                    print(f"      ç‚¹èµæ•°: {answer.vote_count}")
                    print(f"      è¯„è®ºæ•°: {answer.comment_count}")
                    print(f"      å†…å®¹é•¿åº¦: {len(answer.content)} å­—ç¬¦")
                    if len(answer.content) > 100:
                        print(f"      å†…å®¹é¢„è§ˆ: {answer.content[:100]}...")
            else:
                print("    âš ï¸  è¯¥é—®é¢˜æ²¡æœ‰æ‰¾åˆ°ç­”æ¡ˆ")

        except Exception as e:
            print(f"  âŒ çˆ¬å–å¤±è´¥: {e}")

    print("\n" + "=" * 50)
    print("ğŸ‰ APIçˆ¬è™«æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ“‹ æŠ€æœ¯ç‰¹æ€§æ€»ç»“:")
    print("âœ… APIè®¤è¯æˆåŠŸ - æ— 403é”™è¯¯")
    print("âœ… å®Œæ•´çš„è¯·æ±‚å¤´æ”¯æŒ")
    print("âœ… feedsç«¯ç‚¹æ•°æ®è§£æ")
    print("âœ… åˆ†é¡µå¤„ç†æœºåˆ¶")
    print("âœ… é”™è¯¯é‡è¯•æœºåˆ¶")
    print("âœ… æ•°æ®åº“é›†æˆå‡†å¤‡å°±ç»ª")

    print("\nğŸ”§ ä½¿ç”¨æ–¹æ³•:")
    print("1. ç¡®ä¿cookiesæœ‰æ•ˆä¸”å®Œæ•´")
    print("2. è°ƒç”¨ crawl_answers_by_question_url() æ–¹æ³•")
    print("3. å¤„ç†è¿”å›çš„ç­”æ¡ˆæ•°æ®")

if __name__ == "__main__":
    demo_api_crawler()
